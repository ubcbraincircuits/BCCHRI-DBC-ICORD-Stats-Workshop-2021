Generate some data
Let's generate some data using three different calls to the rnorm function to represent samples from three different populations.
```{r}
#Use a sample size of 20 for all of the samples. Set the mean of the first two samples as 2 and set the 
#mean of the last sample as 4. Use a standard deviation of 1.5 for all samples. 
x1=rnorm(20, mean=2, sd=1.5)
x2=rnorm(20, mean=2, sd=1.5)
x3=rnorm(20, mean=4, sd=1.5)

# Lets look at the mean and spread of each of our samples using the boxplot() function. 
boxplot(x1,x2,x3)
```

The ANOVA function is a little bit different from the other functions in that it works best when your data is organized a certain way. Luckily, this is the way your data will usually be organized after collection anyway.
```{r}
# lets bind the example data into a dataframe using cbind(). 
data = data.frame(cbind(x1,x2,x3))

#Then we are going to reorganize it with stack. 
data = stack(data)

#And rename the "ind" column. 
data["group"]=data["ind"]
data = subset(data, select=-c(ind))
```

ANOVA
we are going to learn ANOVA in a kind of backwards way. We are going to start by actually conducting an ANOVA test and then we are going to use R to explore what all of the different outputs mean. 

```{r}
# In order to run an ANOVA test, we are going to need to use R's linear regression function lm()
# Why are we using linear regression for ANOVA? because ANOVA is actually a special application of Linear
# Regression! We may explore this more in future workshops, but for now do not worry about it. 

#run help(lm)
help(lm)

# wait, what is a formula class object? 
# Formula class obects are specified using a tilde (~) and are used to specify a relationship between two
# vectors.
# Essentially, when you type A~B you are saying thet you want to test if variable A is dependent on B.
# The first term is the response variable in your data and the second is the explanatory variable. 
# The specifics of what a formula object actually is in R are complicated and beyond this workshop. 
# for more details, look up ?formula 

# ok, now we can actually use lm() by specifying the formula and data arguments. run lm and save the 
# output in a variable
# Hint: what are our response and explanatory variables? 
Av_object <- lm(values~group,data=data) 

# Now we are ready to actually run the ANOVA test using the anova() function. 
anova(Av_object)
```
Let's hop over to the slides so we can look at this output more closely. 

The most important output from our table is the F-statistic. The F-statsitc measures the amount of variation in our data that came from differences between our treatment groups versus the amount of variation that came from differences within our treatment groups. From this F statistic we can create an f distribution that allows us to calculate P-values. 
```{r}
# lets create the F distribution using the df function.
# It works almost exactly like the dt function but with 2 inputs for degrees of freedom. 
# One for the residual (or error) degrees of freedom and one for the 
x=seq(0,6,by=0.001)
fdistr=df(x,df1 = 2, df2 = 57)


plot(x,fdistr,type="l",
     xlim = c(0,5), 
     ylim = c(0,1),
     xlab="F",
     ylab="Probability Density",
     main =" F distribution with 2 and 57 degrees of freedom (df)")

polygon(c(x[x>=3.15], max(x), 3.15), c(fdistr[x>=3.15], 0, 0), col="red")
```
Multiple Comparisons

There are a large variety of different multiple comparison tests that can be performed in R. These tests use a variety of complicated mathematics to get around the the increased chance of type 1 error caused by running multiple tests. 

```{r}
# The first test we will try out is the TukeyHSD test (probably the most common form of multiple 
# comparison). 

# Before even attempting this test, it is important to run an ANOVA test first!
Av_object <- lm(values~group,data=data)
anova(Av_object)

# If our ANOVA finds that at least one mean is significantly different, then we can conduct a Tukey 
# Kramer test using TukeyHSD. 
TukeyHSD(aov(Av_object), conf.level=0.95)
```
Other multiple comparisons in r utilize a function called pairwise.t.test. This function is used to perform multiple two-sample t-tests between all of the different sample groups, so it does that thing I told you never to do. Luckily, it has an option to adjust the P-values of these t-tests based on different multiple comparison methods. 
```{r}
# try running help("pairwise.t.test")
help("pairwise.t.test")
# rather than using a formula object, you just specify the two vectors you are looking at. 

#perform a pairwise t-test using the Bonferroni method ("bonf")
pairwise.t.test(data$values, data$group, p.adj = "bonf",alternative="two.sided")

# Unfortunaetely, the output of pairwise.t.test is different from TukeyHSD, but it is not too hard to 
# understand. 
```

```{r}
#finally, let's perform a pairwise t-test using the BH method ("BH")
pairwise.t.test(data$values, data$group, p.adj = "BH",alternative="two.sided")
```