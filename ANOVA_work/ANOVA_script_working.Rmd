Generate some data
Let's generate some data using three different calls to the rnorm function to represent samples from three different populations.
```{r}
#Use a sample size of 20 for all of the samples. Set the mean of the first two samples as 2 and set the 
#mean of the last sample as 4. Use a standard deviation of 1.5 for all samples. 
x1=
x2=
x3=

# Lets look at the mean and spread of each of our samples using the boxplot() function. 

```

The ANOVA function is a little bit different from the other functions in that it works best when your data is organized a certain way. Luckily, this is the way your data will usually be organized after collection anyway.
```{r}
# lets bind the example data together using cbind() and then put it into a dataframe with data.frame(). 
# let's call our new dataframe df. 
data = 

# Then we are going to reorganize it with stack(). 
data = 

# now are data is all set for ANOVA.
```

ANOVA
we are going to learn ANOVA in a kind of backwards way. We are going to start by actually conducting an ANOVA test and then we are going to use R to explore what all of the different outputs mean. 

```{r}
# In order to run an ANOVA test, we are going to need to use R's linear regression function lm()
# Why are we using linear regression for ANOVA? because ANOVA is actually a special application of Linear
# Regression! We may explore this more in future workshops, but for now do not worry about it. 

#run help(lm). Focus on the first two arguments. 

# wait, what is a formula class object? 
# Formula class obects are specified using a tilde (~) and are used to specify a relationship between two
# vectors.
# Essentially, when you type A~B you are saying thet you want to test if variable A is dependent on B.
# The first term is the response variable in your data and the second is the explanatory variable. 
# The specifics of what a formula object actually is in R are complicated and beyond this workshop. 
# for more details, look up ?formula 

# ok, now we can actually use lm() by specifying the formula and data arguments. run lm and save the 
# output in a variable named Av_object
# Hint: what are our response and explanatory variables? 
Av_object <- 

# Now we are ready to actually run the ANOVA test using the anova() function. 

```
Let's hop over to the slides so we can look at this output more closely. 

The most important output from our table is the F-statistic. The F-statsitc measures the amount of variation in our data that came from differences between our treatment groups versus the amount of variation that came from differences within our treatment groups. From this F statistic we can create an f distribution that allows us to calculate P-values. 
```{r}
# lets create the F distribution using the df function.
# run help(df) and focus on the first 3 arguments. 

# It works almost exactly like the dt function but with 2 inputs for degrees of freedom. 
# df1 is the group degrees of freedom and df2 is for the error degrees of freedom. 
x=
fdistr=

# Now lets plot the F distribution. 

# run this line of code to look at the rejection region
polygon(c(x[x>=3.15], max(x), 3.15), c(fdistr[x>=3.15], 0, 0), col="red")

# Scroll back up to our table, where does your F value fall on this graph? does it make sense that you were/were'nt able to reject the null?
```
Multiple Comparisons

There are a large variety of different multiple comparison tests that can be performed in R. These tests use a variety of different techniques to adjust P-values. 

Many multiple comparisons in r utilize a function called pairwise.t.test. This function is used to perform multiple two-sample t-tests between all of the different sample groups, so it does that thing I told you never to do. Luckily, it has an option to adjust the P-values of these t-tests based on different multiple comparison methods. 
```{r}
# try running help("pairwise.t.test")

# rather than using a formula object, you just specify the two vectors you are looking at. 

#for educational purposes, lets do a pairwise t-test with NO P value adjustment whatsoever ("none"). 

```
```{r}
#now perform a pairwise t-test using the Bonferroni method ("bonf")

# Can you see the difference between the two P-values? 
```

Let's look at what is actually happening with our adjusted P values. 3.85 is the adjusted critical value for sample size = 20 and 50 groups. 
```{r}
#create a t-distribution just like what we did in the t-test section.

# Add the code below to your plot to create a rejection region using our altered P-value. 
# + polygon(c(x[x>=3.85], max(x), 3.85), c(tdistr[x>=3.85], 0, 0), col="red") #

# can you even see the rejection region? let's draw a line to make it more clear
# + abline(v=3.85, col="red") #

# look how small it is! You would need a very large effect or a lot of power to find any significant 
# results. What if we want more power for our experiment? 

```

The Benjamini-Hochberg (BH) method

The Benjamini-Hochberg method is more of an algorithm than an equation. We are going to use tables to visualize how the method decides which P-values are going to stay significant and which we are going to decide are no longer significant. 


```{r}
# We are going to need to load a package called dplyr for this. 
library(dplyr)

# We are going to create a set of P-values that we theoretically could have gotten from performing 10 
# tests. 
p_values=c(0.38,0.22,0.45,0.04,0.06,0.008,0.001,0.15,0.013,0.59)

# then, the first step of the Benjamini Hochberg method is to order the P-values from largest to 
# smallest. We are going to do this using the sort() function. Call this sorted vector p_sort
p_sort=

# Now we are going to create a rank for every p-value. create a list from 1 to 10 using c(). 
rank=

# Now use cbind to bind the rank and the sorted P-values into a dataframe (should be similar to what we # did at te beginning of the markdown file.)
df = 

#The last step is the most important one. We are going to compare our ordered P-values to a set of BH 
# critical values. BH critical values are calculated as i/m*Q where
# i = the rank of the test. 
# m = the total number of tests. 
# Q equals the false discovery rate we are aiming for (0.05)

# now, we will use the mutate function to create a new column with the critical values for each test.
# The mutate function takes the values from other columns and uses an equation to calculate the values 
# for a new column. 
# the mutate function is in the form mutate(dataframe, new_column name = equation)
df = 
df

# Let's look at our dataframe. 
```

Now that we know what the test is doing, we can  just get R to run it. 

```{r}
#finally, let's perform a pairwise t-test using the BH method ("BH")


# compare this output to the output we got from the Bonferroni method. 
```
