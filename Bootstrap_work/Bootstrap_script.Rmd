load the distribution

```{r}
load("dat.rda")
#this is something non-gaussian that I made up.  Meant to mimic a non-normal sample data set with 1550  
#data points. Let's take a look at it using hist.
hist(dat,breaks=30)
```

## NB: R has some built in functions for doing resampling, bootstraping, etc
And there are more online... I will mention a few of them as we go. We will also write some ourselves but I am not going to make any attempt to make this efficient or elegant. For learning purposes we are going to do things more or less by hand. With a computer.

## make a resample.
```{r}
# what does that mean?

# Draw samples with replacement (ie, they don't have to be unique) from the
# data.

# every value in our data table has an index number that can be used to pull that value out of the 
# dataframe. By creating a random set of index values with replacement we can pull a random set of data 
# points out of the dataset with replacement. 

# So we need a bunch of integers between 1 and 1550?  Simplest way to get
# them is the R sample.int command with replacement specified. 

# example for 10 values from 1 - 10:

print(sample.int(10,10,replace=TRUE))

# notice how some numbers come up twice while other never come up? that is replacement. 

# So the indices (store in a variable called ind) for our resample can be 
# found like this:
ind=sample.int(1550,1550,replace=TRUE) 

# or get R to get the size of the sample using num el
ind=sample.int(length(dat),length(dat),replace=TRUE)

# So to get our resample all we need to do is index dat with ind and assign
# the result to a new variable.  Call it dat_RS.
dat_RS=dat[ind]
```

take a look at our resample:
Use hist!

```{r}
hist(dat_RS,breaks=30)

#unless you get a peculiar resample it should look pretty much like the
#original one.
```
##So now I am going to write you a function to do the resampling for you many times over. 

```{r}
# Use 2 inputs. 1. the data, can be called dat 2. the number of resamples, nresamps.
# Store your resamples in a matrix as output, call it resamps_out.  Remember to
# comment your code!!

make_resamples = function(dat,nresamps){
#make_samples function returns nresamps of data stored in dat
#inputs:
# dat: this is the data, should be a 1xn matrix
# nresamps: this is how many resamples we will calculate
# outputs:
# resamps_out: this is an nresamps x n matrix, stores all of our resamples.

resamps_out=matrix(nrow=nresamps,ncol=length(dat))

for (i in 1:nresamps) {
    #generate random numbers for resample
    ind=sample.int(length(dat),length(dat),replace=TRUE)
    # index data with new indices
    dat_RS=dat[ind]
    # store in output matrix
    resamps_out[i,]=dat_RS
}
    return(resamps_out)
}
```
# This function returns a 2 dimensional matrix of resamples. What is a 2 dimensional matrix? For our purposes it is a table. Just a table. Sounds fancy. Really boring. 

```{r}
# Write a command using our function to do 10 resamples.

dat_RS=make_resamples(dat,10)

# take a look at the resamples to see how their histograms look, do a loop
# and a subplot.

par(mfrow=c(2,5))
for (i in 1:10) {
    hist(dat_RS[i,],breaks=20,main="",xlab="",ylab="")
}
# Pretty similiar??  Should be...
```
ok, now that we can generate lots of resamples let's look at the distribution of different means in our resamples.
#!!!!# make sure to be clear about the fact that each of these resamples (refer to the histograms above) are going to have their means calculated. 
```{r}
# let's get 2000 resamples

dat_RS=make_resamples(dat,2000)

# easy to find the mean of the resamples. we are going to use the apply function to calculate the mean for every resample in our matrix. 

avg_RS=apply(dat_RS,1,mean)

# So now we have the mean for each resample.  plot the distribution of
# that using hist again.

hist(avg_RS,breaks=30,main="Bootstrap distribution")

# Btw, what was our actual sample mean?

mean(dat)
# it is the same of the mean of this histogram isn't it? 
```
Where do you expect this to fall on the histogram?  What shape should this
distribution have? #!!!!# the hell does this mean? 

What is this distribution?

It's the bootstrap distriubtion of the sample mean. It represents an estimation of the sampling 
distribution. 

Let's try it again, this time using R's most popular bootstrapping package which is creatively named 
boot. 
```{r}
#Check the boot package doc using help("boot") There is a lot of information in this help file, but you 
#should focus on the first 3 inputs. Use the function to find the means of 2000
#resamples. store the result in a matrix called m for mean.

library(boot)

# The statistic input is not intuitive, so I have added in a function that is the proper input.
samplemean <- function(data, i) {
  d=data[i]
  return(mean(d))
}

output = boot(data=dat,statistic=samplemean,R=2000); #!!!!# I need to find a better way to guide them to finding out that they need the t part of output. 
m = output$t
```
Let's head back to the slides for now. 


Now that we have the bootstrap distribution, we can use it to estimate all kinds of useful stuff. 

How about the standard error?

```{r}
# using our bootstrap distribution, call it avg_RS_se
# remeber, the standard deviation function in R is sd()
avg_RS_se=sd(avg_RS)
# Using the bootstrap distribution from boot, call it m_se. 
m_se=sd(m)
```

And confidence intervals?

```{r}
# a few different options here: option 1.  My sampling distribution looks
# Normal.  Then you can use critical t values and all is well.

#!!!# I think I should mention that
# familiar equation stat +/- t*SE_stat 
# for alpha=0.05;
alpha=0.05
tcrit = qt(1-alpha/2,1550);
mean(m)-tcrit*sd(m)
mean(m)+tcrit*sd(m)

# Ok, but what if it is not Normal?  Then what? 
# Then you can look at the percentiles to make a CI #!!!!!# hmmm, I was under the impression that it still needs to be normal for this? 

per_ci=boot.ci(output, type="perc")
print(per_ci)
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.

print(length(which(m>per_ci$percent[,4] & m < per_ci$percent[,5]))/length(m))

# Nice.  Willing to except a little descrepancy here since the bootci is
# calculating a new bootstrap distribution compared to the one we used for
# m.
#!!!# This is kind of weird, shouldn't we just use the same bootstrap somehow? 

# or perhaps use the bias corrected accelerated confidence interval?
bca_ci=boot.ci(output, type="bca")
print(bca_ci)
# It adjusts to correct for bias and skewness in the bootstrap distribution.
```
Before we get into Permutation testing, I am going to remake my resampling function so that we can get resamples with a specific number of data points. I am going to call it make_resamples2

```{r}
make_resamples2 = function(dat,nresamps,nsamps) {
#make_resamples This function resamples an input data set a specified
#number of times
# inputs:
# dat: 1xn matrix/vector containing the data to resample.
# nresamps: the number of resamples to do.
# nsamp: number of data point in the resample.  
# 
# outputs
#resamps_out: nresamps x nsamp matrix containg the nresamps resamples of dat.
#each resample has nsamp data points.

# ok.  First step is to prep the output matrix. This just creates an empty matrix. 
resamps_out=matrix(nrow=nresamps,ncol=nsamps)

# Now we can use a loop to create the resmaples using our couple lines of
# code from before.

# loop starts at one and goes to nresamps
    
    for (i in 1:nresamps) {
    #generate random numbers for resample
    ind=sample.int(length(dat),nsamps,replace=FALSE) #!!!# Wait, are we doing replacement here? 
    # index data with new indices
    dat_RS=dat[ind]
    # store in output matrix
    resamps_out[i,]=dat_RS
}
    return(resamps_out)
}

```

Permutation testing.

```{r}
#Let's make a couple of normal samples.  Call them x1 and x2.
# give x1 a mean of 1 and a std of 2 and 27 data points
# give x2 a mean of 2 and a std of 3 and 47 data points
# recall the R function rnorm gives random numbers taken from a
# normal distribution.

x1=rnorm(27, mean=1, sd=2) 
x2=rnorm(47, mean=2, sd=2)

# take a look at each of them using hist.

hist(x1, main="Sample 1",xlab="")
hist(x2, main="Sample 2",xlab="")

```



```{r}
# and we want to look at the difference of the means? So calculate the
# observed difference from the samples.  Store in x_diff_obs.

x_diff_obs=mean(x2)-mean(x1)

# ok our null hypothesis is that there is no difference between the means
# of the two samples.  So we can build a distribution by resampling as if
# this were the case.  Call it the permutation distribution to distinguish 
# it from the bootstrap.  We have a total of 27 + 47=74 observtions.  Let's put
# them all together in a big vector by concatenation, call it x:

x=c(x1, x2) # !!!# I may have to provide an example of how to concatonate. 

# Check it by making a single resample. For x1 the extra argument should be
# 27 (length(x1)) & it should be 47 (length(x2)) for x2

x1_RS=make_resamples2(x,1,length(x1)) #!!!!# I need to make sure that I explain this part a lot, This is the most confusing part (in my opinion)
x2_RS=make_resamples2(x,1,length(x2))

# now make say 5000 resamples.

x1_RS=make_resamples2(x,5000,length(x1));
x2_RS=make_resamples2(x,5000,length(x2));

# find the means and subtract them, take the mean on the data points.
# Second dimension.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)

x_diff=x1_RS_avg-x2_RS_avg;

# make a histogram to have a look at the distribution

hist(x_diff,breaks=30,main = "Permutation Distribution")

# now figure out our p val.

# Assuming our alternate hypothesis is that mean of x2 > mean of x1

print(length(which(x_diff >= x_diff_obs))/length(x_diff))

#should be <0.05 for significance at alpha =0.05
#!!!!! # No function to perform a permutation test? 
```
```{r}
hist(x, main="Combined Sample",xlab="")
x1_RS=make_resamples2(x,1,length(x1)) #!!!!# I need to make sure that I explain this part a lot, This is the most confusing part (in my opinion)
x2_RS=make_resamples2(x,1,length(x2))
hist(x1_RS, main="Resample 1",xlab="")
hist(x2_RS, main="Resample 2",xlab="")
```
