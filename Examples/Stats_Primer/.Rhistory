# specific number of data points.  Start by saving your function with a new
# name make_samples2.  Don't forget to rename the function.  Add an extra
# input argument called nsamp which will be the number of data points in
# the resample.  Don't forget to update your comments.
make_resamples2 = function(dat,nresamps,nsamps) {
#make_resamples This function resamples an input data set a specified
#number of times
# inputs:
# dat: 1xn matrix/vector containing the data to resample.
# nresamps: the number of resamples to do.
# nsamp: number of data point in the resample.
#
# outputs
#resamps_out: nresamps x nsamp matrix containg the nresamps resamples of dat.
#each resample has nsamp data points.
# ok.  First step is to prep the output matrix, I usually use zeros for
# this.
resamps_out=matrix(nrow=nresamps,ncol=nsamps)
# Now we can use a loop to create the resmaples using our couple lines of
# code from before.
# loop starts at one and goes to nresamps
for (i in 1:nresamps) {
#generate random numbers for resample
ind=sample.int(length(dat),nsamps,replace=TRUE)
# index data with new indices
dat_RS=dat[ind]
# store in output matrix
resamps_out[i,]=dat_RS
}
return(resamps_out)
}
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 500 resamples.
x1_RS=make_resamples2(x,500,length(x1));
x2_RS=make_resamples2(x,500,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
length(which(x_diff >= x_diff_obs))/length(x_diff)
#should be <0.05 for significance at alpha =0.05
which(x_diff >= x_diff_obs)
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 500 resamples.
x1_RS=make_resamples2(x,500,length(x1));
x2_RS=make_resamples2(x,500,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
length(which(x_diff >= x_diff_obs))/length(x_diff)
#should be <0.05 for significance at alpha =0.05
#Let's make a couple of normal samples.  Call them x1 and x2.
# give x1 a mean of 1 and std of 2 and 27 data points
# give x2 a mean of 2 and std of 3 and 47 data points
# recall the R function rnorm gives random numbers taken from a
# normal distribution.
x1=2*rnorm(27)+1
x2=3*rnorm(47)+2
# take a look at each of them using hist.
hist(x1)
hist(x2)
# add we want to look at the difference of the means? So calculate the
# observed difference from the samples.  Store in x_diff_obs.
x_diff_obs=mean(x2)-mean(x1)
# ok our null hypothesis is that there is no difference between the means
# of the two samples.  So we can build a distribution by resampling as if
# this were the case.  Call it the permutation distribution to distinguish
# it from the bootstrap.  We have a total of 27 + 47=74 observtions.  Let's put
# them all together in a big vector by concatenation, call it x:
x=c(x1, x2)
# now let's modify our make_resamples so that we can get resamples with a
# specific number of data points.  Start by saving your function with a new
# name make_samples2.  Don't forget to rename the function.  Add an extra
# input argument called nsamp which will be the number of data points in
# the resample.  Don't forget to update your comments.
make_resamples2 = function(dat,nresamps,nsamps) {
#make_resamples This function resamples an input data set a specified
#number of times
# inputs:
# dat: 1xn matrix/vector containing the data to resample.
# nresamps: the number of resamples to do.
# nsamp: number of data point in the resample.
#
# outputs
#resamps_out: nresamps x nsamp matrix containg the nresamps resamples of dat.
#each resample has nsamp data points.
# ok.  First step is to prep the output matrix, I usually use zeros for
# this.
resamps_out=matrix(nrow=nresamps,ncol=nsamps)
# Now we can use a loop to create the resmaples using our couple lines of
# code from before.
# loop starts at one and goes to nresamps
for (i in 1:nresamps) {
#generate random numbers for resample
ind=sample.int(length(dat),nsamps,replace=TRUE)
# index data with new indices
dat_RS=dat[ind]
# store in output matrix
resamps_out[i,]=dat_RS
}
return(resamps_out)
}
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 500 resamples.
x1_RS=make_resamples2(x,500,length(x1));
x2_RS=make_resamples2(x,500,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
length(which(x_diff >= x_diff_obs))/length(x_diff)
#should be <0.05 for significance at alpha =0.05
print(length(which(x_diff >= x_diff_obs))/length(x_diff))
boot?
boot?
boot?
help(boot)
help("boot")
hist(dat_RS,breaks=30)
#unless you get a peculiar resample it should look pretty much like the
#original one.
View(per_ci)
# a few different options here: option 1.  My sampling distribution looks
# Normal.  Then you can use critical t values and all is well.
#!!!!# Make sure to have already mentioned this equation in the slides somewhere during the t-test
#!!!!# section if you are going to call it familiar
# familiar equation stat +/- t*SE_stat
# for alpha=0.05;
alpha=0.05
tcrit = qt(1-alpha/2,1550);
mean(m)-tcrit*sd(m)
mean(m)+tcrit*sd(m)
# Ok, but what if it is not Normal?  Then what?
# Then you can look at the percentiles to make a CI
per_ci=boot.ci(output, type="perc")
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
#length(which(m>per_ci(1) & m < per_ci(2)))/numel(m)
# Nice.  Willing to except a little descrepancy here since the bootci is
# calculating a new bootstrap distribution compared to the one we used for
# m.
# or perhaps use the bias corrected accelerated confidence interval?
bca_ci=boot.ci(output, type="bca")
# It adjusts to correct for bias and skewness in the bootstrap distribution.
# a few different options here: option 1.  My sampling distribution looks
# Normal.  Then you can use critical t values and all is well.
#!!!!# Make sure to have already mentioned this equation in the slides somewhere during the t-test
#!!!!# section if you are going to call it familiar
# familiar equation stat +/- t*SE_stat
# for alpha=0.05;
alpha=0.05
tcrit = qt(1-alpha/2,1550);
mean(m)-tcrit*sd(m)
mean(m)+tcrit*sd(m)
# Ok, but what if it is not Normal?  Then what?
# Then you can look at the percentiles to make a CI
print(per_ci=boot.ci(output, type="perc"))
# a few different options here: option 1.  My sampling distribution looks
# Normal.  Then you can use critical t values and all is well.
#!!!!# Make sure to have already mentioned this equation in the slides somewhere during the t-test
#!!!!# section if you are going to call it familiar
# familiar equation stat +/- t*SE_stat
# for alpha=0.05;
alpha=0.05
tcrit = qt(1-alpha/2,1550);
mean(m)-tcrit*sd(m)
mean(m)+tcrit*sd(m)
# Ok, but what if it is not Normal?  Then what?
# Then you can look at the percentiles to make a CI
per_ci=boot.ci(output, type="perc")
print(per_ci)
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
#length(which(m>per_ci(1) & m < per_ci(2)))/numel(m)
# Nice.  Willing to except a little descrepancy here since the bootci is
# calculating a new bootstrap distribution compared to the one we used for
# m.
# or perhaps use the bias corrected accelerated confidence interval?
bca_ci=boot.ci(output, type="bca")
print(bca_ci)
# It adjusts to correct for bias and skewness in the bootstrap distribution.
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[1]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[2]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[3]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4][1]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4][1,2]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4][1][1]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4,1]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci["percent conf"]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci[4]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci$percent
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci$percent[,2]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci$percent[,3]
# Does it make sense?  Figure out how many elements in our bootstrap
# distribution fall within these limits.  Use numel and find perhaps.
per_ci$percent[,4]
length(which(m>per_ci$percent[,4] & m < per_ci$percent[,5]))/length(m)
print(length(which(m>per_ci$percent[,4] & m < per_ci$percent[,5]))/length(m))
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 5000 resamples.
x1_RS=make_resamples2(x,5000,length(x1));
x2_RS=make_resamples2(x,5000,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
print(length(which(x_diff >= x_diff_obs))/length(x_diff))
#should be <0.05 for significance at alpha =0.05
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 5000 resamples.
x1_RS=make_resamples2(x,5000,length(x1));
x2_RS=make_resamples2(x,5000,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
print(length(which(x_diff >= x_diff_obs))/length(x_diff))
#should be <0.05 for significance at alpha =0.05
make_resamples2 = function(dat,nresamps,nsamps) {
#make_resamples This function resamples an input data set a specified
#number of times
# inputs:
# dat: 1xn matrix/vector containing the data to resample.
# nresamps: the number of resamples to do.
# nsamp: number of data point in the resample.
#
# outputs
#resamps_out: nresamps x nsamp matrix containg the nresamps resamples of dat.
#each resample has nsamp data points.
# ok.  First step is to prep the output matrix, I usually use zeros for
# this.
resamps_out=matrix(nrow=nresamps,ncol=nsamps)
# Now we can use a loop to create the resmaples using our couple lines of
# code from before.
# loop starts at one and goes to nresamps
for (i in 1:nresamps) {
#generate random numbers for resample
ind=sample.int(length(dat),nsamps,replace=TRUE)
# index data with new indices
dat_RS=dat[ind]
# store in output matrix
resamps_out[i,]=dat_RS
}
return(resamps_out)
}
#Let's make a couple of normal samples.  Call them x1 and x2.
# give x1 a mean of 1 and std of 2 and 27 data points
# give x2 a mean of 2 and std of 3 and 47 data points
# recall the R function rnorm gives random numbers taken from a
# normal distribution.
x1=2*rnorm(27)+1
x2=3*rnorm(47)+2
# take a look at each of them using hist.
hist(x1)
hist(x2)
# and we want to look at the difference of the means? So calculate the
# observed difference from the samples.  Store in x_diff_obs.
x_diff_obs=mean(x2)-mean(x1)
# ok our null hypothesis is that there is no difference between the means
# of the two samples.  So we can build a distribution by resampling as if
# this were the case.  Call it the permutation distribution to distinguish
# it from the bootstrap.  We have a total of 27 + 47=74 observtions.  Let's put
# them all together in a big vector by concatenation, call it x:
x=c(x1, x2)
make_resamples2 = function(dat,nresamps,nsamps) {
#make_resamples This function resamples an input data set a specified
#number of times
# inputs:
# dat: 1xn matrix/vector containing the data to resample.
# nresamps: the number of resamples to do.
# nsamp: number of data point in the resample.
#
# outputs
#resamps_out: nresamps x nsamp matrix containg the nresamps resamples of dat.
#each resample has nsamp data points.
# ok.  First step is to prep the output matrix, I usually use zeros for
# this.
resamps_out=matrix(nrow=nresamps,ncol=nsamps)
# Now we can use a loop to create the resmaples using our couple lines of
# code from before.
# loop starts at one and goes to nresamps
for (i in 1:nresamps) {
#generate random numbers for resample
ind=sample.int(length(dat),nsamps,replace=TRUE)
# index data with new indices
dat_RS=dat[ind]
# store in output matrix
resamps_out[i,]=dat_RS
}
return(resamps_out)
}
# Check it by making a single resample. For x1 the extra argument should be
# 27 numel(x1) & should 47 (numel(x2)) for x2
x1_RS=make_resamples2(x,1,length(x1))
x2_RS=make_resamples2(x,1,length(x2))
# now make say 5000 resamples.
x1_RS=make_resamples2(x,5000,length(x1));
x2_RS=make_resamples2(x,5000,length(x2));
# find the means and subtract them, take the mean on the data points.
# Second dim.
x1_RS_avg=apply(x1_RS,1,mean)
x2_RS_avg=apply(x2_RS,1,mean)
x_diff=x1_RS_avg-x2_RS_avg;
# make a histogram to have a look at the distribution
hist(x_diff,breaks=20)
# now figure out our p val.
# Assuming our alternate hypothesis is that mean of x2 > mean of x1
print(length(which(x_diff >= x_diff_obs))/length(x_diff))
#should be <0.05 for significance at alpha =0.05
# let's get 2000 resamples
dat_RS=make_resamples(dat,2000)
# easy to find the mean of the resamples.  Use mean and specify the second
# dimension.  Store the result in avg_RS
avg_RS=apply(dat_RS,1,mean)
# So now we have the mean for each resample.  plot the distribution of
# that using hist again.
hist(avg_RS,breaks=30)
# Btw, what was our actual sample mean?
mean(dat)
#lets create a super basic sampling distribution using R's rnorm function.
x = rnorm(1000)
hist(x)
#lets create a super basic sampling distribution using R's rnorm function.
x = rnorm(1000)
hist(x, breaks=30)
#lets create a super basic sampling distribution using R's rnorm function.
x = rnorm(5000)
hist(x, breaks=30)
#lets create a super basic sampling distribution using R's rnorm function.
x = rnorm(10000)
hist(x, breaks=30)
#What's our t distribution look like?
tdistr=dt(seq(-5,5,by=.1),length(x))
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution",xlab="",ylab="")
# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?
obs_t=(mean(x)-10)/(sd(x)/sqrt(length(x)))
# R's t test function is called t.test
# do the t.test:
t.test(x,mu=10,alternative="g")
# There are a lot of outputs, but for our purposes we want to focus on
# the p-value.
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 2.5, sd = 0.5)
plot(x,y)
#lets create a super basic sampling distribution and then draw a bunch of samples from it using the rnorm function.
x = rnorm(10000)
hist(x, breaks=30)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 2.5, sd = 0.5)
plot(x,y,type=l)
plot(x,y,type='l')
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 2.5, sd = 2)
plot(x,y,type='l')
#lets create a super basic sampling distribution and then draw a bunch of samples from it using the rnorm function.
x = rnorm(10000)
hist(x, breaks=30)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 2.5, sd = 2, ylab='Probability', xlab='Sample Statistic')
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 2.5, sd = 2)
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#lets create a super basic sampling distribution and then draw a bunch of samples from it using the rnorm function.
x = rnorm(10000)
hist(x, breaks=30)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(-10, 10, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#lets create a super basic sampling distribution and then draw a bunch of samples from it using the rnorm function.
x = 2.5*rnorm(10000)+10
hist(x, breaks=30)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#lets create a super basic sampling distribution and then draw a bunch of samples from it using the rnorm function.
x = 2.5*rnorm(10000)+10
hist(x, breaks=30)
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
#Now lets draw a bunch of samples from the distribution.
x = 2.5*rnorm(10000)+10
hist(x, breaks=30)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
#Now lets draw a bunch of samples from the distribution.
x = 2.5*rnorm(10000)+10
hist(x, breaks=30)
# lets create a super basic probability distribution to represent a sampling distribution
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)
# now we plot the distribution
plot(x,y,type='l', ylab='Probability', xlab='Sample Statistic')
#Now lets draw a single point from this sampling distribution using rnorm
x = 2.5*rnorm(1)+10
print(x)
#Now lets draw a bunch of samples from the distribution.
x = 2.5*rnorm(10000)+10
hist(x, breaks=30, xlab="Sample Statistic")
