One Sample
```{r}
# First set the number of samples to draw from our sampling distribution
n_samples=17

# first make some data points to use via the randn command
# plot it in a histogram to take a look.
x=2.5*rnorm(n_samples)+10

hist(x)

# Let's say the test we are trying to accomplish it to see if the data is
# consistent with a population mean of 10.  This will be our H0: mu=10.

# What's our Ha?  
  
# Let's say the alternative is that mu > 10, This means we will be looking
# for our test statistic in a rejection region which is out to the right
# side of the distribution, so we will need to set the greater than option.

#Quickly jump over to chapter 18-13.  Sampling distribution which is true
#under H0.

#What's our t distribution look like?
tdistr=dt(seq(-5,5,by=.1),length(x))
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution",xlab="",ylab="")

# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?

obs_t=(mean(x)-10)/(sd(x)/sqrt(length(x)))

# R's t test function is called t.test

# do the t.test:
t.test(x,mu=10,alternative="g")

# Their are a lot of outputs, but for our purposes we want to focus on 
# the p-value. 
  
# just for funsies:  How often do we make a type I error?  It's
# easy to estimate for type I here.  We know mu.  Above. It's 10.

# So what's a type I error again?  H0 rejected when it's true.
# In our case H0 is true.
# let's generate a sample and do the test lot's of times to see how often
# we reject H0.

N_iter=20000
h_out=0
alpha=0.05
for (i in 1:N_iter){
  x=2.5*rnorm(n_samples)+10
  p=t.test(x,mu=10,alternative="g")[["p.value"]]
  if (p < alpha){
  h_out=h_out+1
  }
  }
# So what's the rate of type I error?

h_out/N_iter

# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!

# Ok that's all for now.  Go back to slides.
```
Two sample T-test.
```{r}

# first make 2 large samples
x=2.5*rnorm(170)+10;
y=2.5*rnorm(340)+11;

# Look at them.

hist(x)
hist(y)

# very cute, but let's reduce the number of data points to make this a
# little more messy, I mean realistic.

x=2.5*rnorm(n_samples)+10;
y=2.5*rnorm(34)+11;

# Look at them.

hist(x)
hist(y)

# Here I made the variances equal.  In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.  

sp=((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp=sqrt(sp)

# and then we need to think about our H0 for a moment.

# let's say our H0 is that the population means are equal.  ie mu1=mu2.  So
# we can calculate our t statistic as follows:
  
obs_t=(mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))

# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mu1 < mu2, That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mu1 < mu2.  Imagine mu1 was 0 and
# mu2 was 1000.  If the samples were large and xbar ~mu1 and ybar ~mu2 then
# tstat would be large and negative! This means to the left.

# ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?

tdistr=dt(seq(-5,5,by=.1),length(x)+length(y)-2)
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution, 2 samp test example",xlab="",ylab="")

# Ok now use the matlab test to confirm our suspicions.

t.test(x,y,var.equal=TRUE, alternative="l")

# Note the test can also be done without assuming the variances are equal

# In this case the t stat is a bit easier to calculate, just as we had in
# the presentation.  No pooled sd.  However the dof is approxiamte and is
# estimated from the data using a formula you can look up.

t.test(x,y,var.equal=FALSE, alternative="l")

# Due to this approximation the test stat is only approximately t
# distributed so you only get approximately alpha significance.

# back to slides for a moment
```
Paired test
```{r}
# ok we need two samples again.

x=2.5*rnorm(n_samples)+10;
y=2.5*rnorm(n_samples)+11;

# same number of data points this time.

# ok, so what are our diffs?
  
the_diffs=x-y

# What's our H0.  Let's say it is that the means are equal again.

# what's our t stat?

obs_t=mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))

# what does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?

tdistr=dt(seq(-5,5,by=.1),length(the_diffs)-1)
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution, paired test example",xlab="",ylab="")

# What's our Ha?  Let's say again that mu1<mu2, so we need to look at a
# rejection region in the left tail of the distribution.

# ok do the test.  it's ttest again

t.test(x,y,paired=TRUE, alternative="l")
```
