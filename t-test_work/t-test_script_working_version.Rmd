#!!!!!# For this script I need to create a bunch of blanks to let people fill stuff in. 
Sampling distributions. 
The sampling distribution of a statistic represents all of the different different sample statistics we could get when we draw a random sample from a population. 
```{r}
# lets create a super basic normal distribution to represent a sampling distribution.
# the mean of our distribution will be 10 and the standard deviation will be 2.5. 
x <- seq(0, 20, by = .1)
y <- dnorm(x, mean = 10, sd = 2.5)

# now we plot the distribution
plot(x,y,type='l', main="Example of a sampling distribution", ylab='Probability',
     xlab='Sample Statistic')

# Now lets draw a single point from an identical sampling distribution using the rnorm function
# If you are not familiar with rnorm, try running help(rnorm) and see what comes up

#Now lets draw a bunch of points from an idential distribution and see what they look like using the 
#hist() function. Try help(hist) if stuck.

```
This shape probably looks familiar to most of you. This is a normal distribution. It is going to come up a lot for reasons we are about to go over. 


The t statistic and the t distribution. 
```{r}
#What does our t distribution look like?
tdistr=dt(seq(-5,5,by=.1),17)
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution",xlab="t",ylab="Porobability Density")

# Let's add a not so random line to represent a theoretical t statistic. 
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution",xlab="t",ylab="Probability Density")+
  abline(v=1.75, col='red')
```
What I just did is sort of like a manual version of conducting a t-test. R has a whole bunch of built in machinery that makes doing t-tests much simpler. Let's actually do a t-test now. 

Let's say the test we are trying to accomplish it to see if the data is
consistent with a population mean of 10.  This will be our H0: mu=10.

What's our Ha?  
  
Let's say the alternative is that mu > 10, This means we will be looking
for our test statistic in a rejection region which is out to the right
side of the distribution, so we will need to set the greater than option.

One Sample T-test. 

```{r}
# First set the sample size we are going to use when we draw our sample. Let's do 20 replicates and call 
# the variable n

# create a sample to use via the rnorm command and call it x. Give it a mean of 10 and a standard  
# deviation of 2.5.  plot it in a histogram and take a look. 
x=

#Quickly remake the t distribution. 
tdistr=dt(seq(-5,5,by=.1),17)
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution",xlab="t",ylab="Porobability Density")

# what's our t value and where is it on the distribution?  What do you predict for the result of
# the test?

obs_t=(mean(x)-10)/(sd(x)/sqrt(length(x)))

# R's t test function is called t.test

# do the t.test:

# There are a lot of outputs, but for our purposes we want to focus on 
# the p-value. 
```
just for funsies:  How often do we make a type I error?  It's
easy to estimate for type I here.  We know mu.  Above. It's 10.

So what's a type I error again?  H0 rejected when it's true.
In our case H0 is true.
let's generate a sample and do the test lot's of times to see how often
we reject H0.
```{r}
N_iter=20000
h_out=0
alpha=0.05
for (i in 1:N_iter){
  x=rnorm(n, mean=10, sd=2.5)
  p=t.test(x,mu=10,alternative="g")[["p.value"]]
  if (p < alpha){
  h_out=h_out+1
  }
  }
# So what's the rate of type I error?

h_out/N_iter

# It should be close to our significance level!  If H0 is true and we
# reject the Null we are out in the tail of distribution by chance.  And
# alpha is the probability of that!

# Ok that's all for now.  Go back to slides.
```
Two sample T-test.

Rather than comparing one sample to a known mean, we are going to compare two samples from slightly different populations to each other. 
```{r}

# first make 2 large samples, lets say 200 and 400 samples each. 
# The mean of x will be 10 and the mean of y will be 11. 
x=
y=

# Look at them using hist().

```
```{r}
# very cute, but let's reduce the number of data points to make this a
# little more messy, I mean realistic. Lets do sample sizes of 20 and 40. 

x=
y=

# Look at them.

hist(x)
hist(y)
```
```{r}

# Here I made the variances equal.  In practice if we are using a two
# sample t test and allowing ourselves to assume equal variances then we
# compute what is called the pooled standard deviation.  

sp=((length(x)-1)*sd(x)^2+(length(y)-1)*sd(y)^2)/(length(x)+length(y)-2)
sp=sqrt(sp)

# and then we need to think about our H0 for a moment.

# let's say our H0 is that the population means are equal.  ie mu1=mu2.  So
# we can calculate our t statistic as follows:
  
obs_t=(mean(x)-mean(y))/sqrt((sp^2)/length(x)+(sp^2)/length(y))

# Now we need to think about our Ha.  Let's say we thought it might be the
# case that mu1 < mu2, That means our t stat would be out there in the left
# tail of the distribution.  Think about an extreme case where we would feel confident
# in saying mu1 < mu2.  Imagine mu1 was 0 and
# mu2 was 1000.  If the samples were large and xbar ~mu1 and ybar ~mu2 then
# tstat would be large and negative! This means to the left.

# ok so what does our t distribution look like?  Where does our observed
# value of t land?  What does that imply for our testing?

tdistr=dt(seq(-5,5,by=.1),length(x)+length(y)-2)
plot(seq(-5,5,by=.1),tdistr,type="l",main="t distribution, 2 samp test example",xlab="",ylab="")

# Ok now use the t.test to confirm our suspicions. look through the help file and figure out how to set 
# the variances as equal

# Note the test can also be done without assuming the variances are equal

# In this case the t stat is a bit easier to calculate, just as we had in
# the presentation.  No pooled sd.  However the dof is approxiamte and is
# estimated from the data using a formula you can look up.
# try running t.test again without specifying that the variances are equal. 

# Due to this approximation the test stat is only approximately t
# distributed so you only get approximately alpha significance.

```
Paired T-test

We are going to look at two samples again, but now we are going to imagine that we are sampling the same individuals from the same population after some kind of treatment. 
```{r}
# ok we need two samples again.

x=
y=

# same number of data points this time.

# ok, so what are our diffs?

# What's our H0.  Let's say it is that the means are equal again.

# what's our t stat?

obs_t=mean(the_diffs)/(sd(the_diffs)/sqrt(length(the_diffs)))

# what does our t distribution look like? Where is our observed t value?
# What's the likely outcome of our test?

# What's our Ha?  Let's say that it is mu1<mu2, so we need to look at a
# rejection region in the left tail of the distribution.

# ok do the test.  it's t.test again but this time we are going to specify that they are paired. 

```
